{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "856b0c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Assistant:\n",
      " None\n",
      "\n",
      "ðŸ› ï¸ Tool Calls:\n",
      "  Tool: get_AIPI_details\n",
      "  Args: {\"query\":\"Brinnae Bent\"}\n",
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fKzwgeiOvD0mOHutFqFXzrzU', function=Function(arguments='{\"query\":\"Brinnae Bent\"}', name='get_AIPI_details'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "from utils.openai_client import get_chat_completion\n",
    "from utils.function_calling import get_response, get_tool_function\n",
    "from tools.tools_schema import TOOLS_SCHEMA\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant for Duke University. You answer questions about Duke's programs, courses, professors, events, and related information using a set of tools. Be thorough, polite, and accurate. If something is unclear, ask follow-up questions to get more context.\n",
    "\n",
    "Guidelines:\n",
    "1. **If a user query is vague or underspecified**, do not assume. Instead, ask follow-up questions. For example, if someone asks \"Who is Dr. Smith?\" ask what program or department they're in before calling a professor-related tool.\n",
    "2. **Use tools only when needed**. Think through the query: Is it about a program, course, professor, or event? Then pick the tool that best fits that need. If a name match seems fuzzy or incorrect, avoid responding with false confidence.\n",
    "3. **Avoid inaccurate tool calls**: For example, if a professor's name does not have an exact match, don't return information about someone with a similar name. Instead, say \"I couldn't find a match â€” could you clarify which program they're associated with?\"\n",
    "4. **For professor-related questions**, try to get their department or program (e.g., AIPI or MEM since you have tools for both) before selecting a tool. Some professors are only listed in specific databases. \n",
    "5. **Use the web search tool** as a fallback for Duke-related queries that don't fit neatly into any other tool (e.g., \"What is Dr. X researching currently?\" or \"What does Duke's housing policy look like?\") OR if the data you get back from the other tools is not helpful, instead of saying \"I dont know\" try to use the web search tool to answer the question. Incase web search doesn't work either, you can use your own knowledge to answer the question.\n",
    "6. You are **not** allowed to answer questions that are not related to Duke University. This is very important. If a user query is **not related to Duke University**, respond by saying it's out of scope and that you're here to help with Duke-related questions.\n",
    "7. Always follow safe and ethical practices when answering questions.\n",
    "8. Provide links, references, and citations when relevant.\n",
    "9. !!!!!!! When asked about the Artificial Intelligence for Product Innovation or AIPI course make sure to use the get_courses tool in your planning !!!!!!!!!\n",
    "10. Use \"pratt_search\" tool to get general information about Pratt School of Engineering and their programs please!.\n",
    "\n",
    "Be concise when appropriate, but offer long, elaborate answers when more detail would be helpful.\n",
    "\"\"\"\n",
    "\n",
    "user_query = \"Who is brinnae bent from the AIPI program?\"\n",
    "\n",
    "tools = TOOLS_SCHEMA\n",
    "tool_choice = 'auto'\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_query}]\n",
    "\n",
    "# Build request kwargs conditionally\n",
    "kwargs = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.1\n",
    "    }\n",
    "\n",
    "if tools:\n",
    "        kwargs[\"tools\"] = tools\n",
    "        kwargs[\"tool_choice\"] = tool_choice\n",
    "\n",
    "try:\n",
    "        response = client.chat.completions.create(**kwargs)\n",
    "        message = response.choices[0].message\n",
    "        print(\"âœ… Assistant:\\n\", message.content)\n",
    "\n",
    "        if message.tool_calls:\n",
    "            print(\"\\nðŸ› ï¸ Tool Calls:\")\n",
    "            for call in message.tool_calls:\n",
    "                print(f\"  Tool: {call.function.name}\")\n",
    "                print(f\"  Args: {call.function.arguments}\")\n",
    "        print(message)\n",
    "except Exception as e:\n",
    "        print(f\"âŒ OpenAI API call failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d5a9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from utils.openai_client import get_chat_completion\n",
    "from tools.tools_schema import TOOLS_SCHEMA\n",
    "from utils.function_calling import get_tool_function, tool_status_messages\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def simulate_tool_loop(user_query):\n",
    "    system_prompt = \"\"\"You are a helpful assistant for Duke University. You answer questions about Duke's programs, courses, professors, events, and related information using a set of tools. Be thorough, polite, and accurate. If something is unclear, ask follow-up questions to get more context.\n",
    "\n",
    "Guidelines:\n",
    "1. **If a user query is vague or underspecified**, do not assume. Instead, ask follow-up questions. For example, if someone asks \"Who is Dr. Smith?\" ask what program or department they're in before calling a professor-related tool.\n",
    "2. **Use tools only when needed**. Think through the query: Is it about a program, course, professor, or event? Then pick the tool that best fits that need. If a name match seems fuzzy or incorrect, avoid responding with false confidence.\n",
    "3. **Avoid inaccurate tool calls**: For example, if a professor's name does not have an exact match, don't return information about someone with a similar name. Instead, say \"I couldn't find a match â€” could you clarify which program they're associated with?\"\n",
    "4. **For professor-related questions**, try to get their department or program (e.g., AIPI or MEM since you have tools for both) before selecting a tool. Some professors are only listed in specific databases. \n",
    "5. **Use the web search tool** as a fallback for Duke-related queries that don't fit neatly into any other tool (e.g., \"What is Dr. X researching currently?\" or \"What does Duke's housing policy look like?\") OR if the data you get back from the other tools is not helpful, instead of saying \"I dont know\" try to use the web search tool to answer the question. Incase web search doesn't work either, you can use your own knowledge to answer the question.\n",
    "6. You are **not** allowed to answer questions that are not related to Duke University. This is very important. If a user query is **not related to Duke University**, respond by saying it's out of scope and that you're here to help with Duke-related questions.\n",
    "7. Always follow safe and ethical practices when answering questions.\n",
    "8. Provide links, references, and citations when relevant.\n",
    "9. !!!!!!! When asked about the Artificial Intelligence for Product Innovation or AIPI course make sure to use the get_courses tool in your planning !!!!!!!!!\n",
    "10. Use \"pratt_search\" tool to get general information about Pratt School of Engineering and their programs please!.\n",
    "\n",
    "Be concise when appropriate, but offer long, elaborate answers when more detail would be helpful.\n",
    "\"\"\"  # truncated for brevity\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    "\n",
    "    max_cycles = 5\n",
    "    for i in range(max_cycles):\n",
    "        print(f\"\\nðŸ” Iteration {i+1} --------------------\")\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            temperature=0.1,\n",
    "            tools=TOOLS_SCHEMA,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "\n",
    "        message = response.choices[0].message\n",
    "\n",
    "        # âœ… If the model returns a content response (no tool call)\n",
    "        if message.content:\n",
    "            print(f\"ðŸ§  Assistant:\\n{message.content}\")\n",
    "            messages.append({\"role\": \"assistant\", \"content\": message.content})\n",
    "            break  # Done\n",
    "\n",
    "        # âœ… If there's a tool call\n",
    "        if message.tool_calls:\n",
    "            tool_call = message.tool_calls[0]\n",
    "            tool_name = tool_call.function.name\n",
    "            tool_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "            print(f\"ðŸ› ï¸ Tool Call: {tool_name}({tool_args})\")\n",
    "            print(tool_status_messages.get(tool_name, \"Running tool...\"))\n",
    "\n",
    "            # Run tool\n",
    "            tool_func = get_tool_function(tool_name)\n",
    "            tool_response = tool_func(**tool_args)\n",
    "\n",
    "            # Append assistant's tool call message\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": None,\n",
    "                \"tool_calls\": [{\n",
    "                    \"id\": tool_call.id,\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tool_name,\n",
    "                        \"arguments\": tool_call.function.arguments\n",
    "                    }\n",
    "                }]\n",
    "            })\n",
    "\n",
    "            # Append tool's response message\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": str(tool_response)\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            print(\"âš ï¸ No tool call or assistant content. Exiting.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edc4e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Iteration 1 --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 12:22:23.422 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Tool Call: get_events({'query': 'zoom'})\n",
      "Getting events...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"client\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LLM - AIPI 590/Duke Student Advisor Chatbot/Duke-Student-Advisor-Chatbot/.venv/lib/python3.12/site-packages/streamlit/runtime/state/session_state.py:454\u001b[39m, in \u001b[36mSessionState.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LLM - AIPI 590/Duke Student Advisor Chatbot/Duke-Student-Advisor-Chatbot/.venv/lib/python3.12/site-packages/streamlit/runtime/state/session_state.py:499\u001b[39m, in \u001b[36mSessionState._getitem\u001b[39m\u001b[34m(self, widget_id, user_key)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m499\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LLM - AIPI 590/Duke Student Advisor Chatbot/Duke-Student-Advisor-Chatbot/.venv/lib/python3.12/site-packages/streamlit/runtime/state/session_state_proxy.py:130\u001b[39m, in \u001b[36mSessionStateProxy.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LLM - AIPI 590/Duke Student Advisor Chatbot/Duke-Student-Advisor-Chatbot/.venv/lib/python3.12/site-packages/streamlit/runtime/state/session_state_proxy.py:101\u001b[39m, in \u001b[36mSessionStateProxy.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    100\u001b[39m require_valid_user_key(key)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LLM - AIPI 590/Duke Student Advisor Chatbot/Duke-Student-Advisor-Chatbot/.venv/lib/python3.12/site-packages/streamlit/runtime/state/safe_session_state.py:96\u001b[39m, in \u001b[36mSafeSessionState.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LLM - AIPI 590/Duke Student Advisor Chatbot/Duke-Student-Advisor-Chatbot/.venv/lib/python3.12/site-packages/streamlit/runtime/state/session_state.py:456\u001b[39m, in \u001b[36mSessionState.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[31mKeyError\u001b[39m: 'st.session_state has no key \"client\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msimulate_tool_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCan you get events on zoom for the next 2 days?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36msimulate_tool_loop\u001b[39m\u001b[34m(user_query)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Run tool\u001b[39;00m\n\u001b[32m     64\u001b[39m tool_func = get_tool_function(tool_name)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m tool_response = \u001b[43mtool_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Append assistant's tool call message\u001b[39;00m\n\u001b[32m     68\u001b[39m messages.append({\n\u001b[32m     69\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     70\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     78\u001b[39m     }]\n\u001b[32m     79\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LLM - AIPI 590/Duke Student Advisor Chatbot/Duke-Student-Advisor-Chatbot/tools/eventsTool.py:224\u001b[39m, in \u001b[36mget_events\u001b[39m\u001b[34m(query, api_key)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_events\u001b[39m(query, api_key=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     filters = \u001b[43mget_event_filters_with_gpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m     groups = filters.get(\u001b[33m\"\u001b[39m\u001b[33mgroups\u001b[39m\u001b[33m\"\u001b[39m, [])\n\u001b[32m    227\u001b[39m     categories = filters.get(\u001b[33m\"\u001b[39m\u001b[33mcategories\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LLM - AIPI 590/Duke Student Advisor Chatbot/Duke-Student-Advisor-Chatbot/tools/eventsTool.py:50\u001b[39m, in \u001b[36mget_event_filters_with_gpt\u001b[39m\u001b[34m(user_prompt, groups, categories)\u001b[39m\n\u001b[32m     21\u001b[39m     system_prompt = \u001b[33m\"\"\"\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe year is 2025. You are an assistant that extracts event filters for an event calendar API. Given a user query and lists of valid \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgroups\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcategories\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, extract:\u001b[39m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[33m1. The number of future days (default to 30 if not mentioned)\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mlocation_keywords\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: [<list of location strings>]\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[33m}\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     38\u001b[39m     messages = [\n\u001b[32m     39\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: system_prompt},\n\u001b[32m     40\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mUser query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_prompt\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m \u001b[33m\"\"\"\u001b[39m}\n\u001b[32m     48\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     response = \u001b[43mget_chat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     content = response.content.strip()\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content.startswith(\u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LLM - AIPI 590/Duke Student Advisor Chatbot/Duke-Student-Advisor-Chatbot/utils/openai_client.py:12\u001b[39m, in \u001b[36mget_chat_completion\u001b[39m\u001b[34m(messages, tools, tool_choice)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_chat_completion\u001b[39m(messages, tools=\u001b[38;5;28;01mNone\u001b[39;00m, tool_choice=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     client = \u001b[43mst\u001b[49m\u001b[43m.\u001b[49m\u001b[43msession_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# Build request kwargs conditionally\u001b[39;00m\n\u001b[32m     15\u001b[39m     kwargs = {\n\u001b[32m     16\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.1\u001b[39m\n\u001b[32m     19\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LLM - AIPI 590/Duke Student Advisor Chatbot/Duke-Student-Advisor-Chatbot/.venv/lib/python3.12/site-packages/streamlit/runtime/state/session_state_proxy.py:132\u001b[39m, in \u001b[36mSessionStateProxy.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[31mAttributeError\u001b[39m: st.session_state has no attribute \"client\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization"
     ]
    }
   ],
   "source": [
    "simulate_tool_loop(\"Can you get events on zoom for the next 2 days?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
